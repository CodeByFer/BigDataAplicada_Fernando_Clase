# An√°lisis Acad√©mico ‚Äì Tarea 1: Primera Inspecci√≥n de los Datos

## Objetivo

El objetivo de esta tarea es realizar una primera inspecci√≥n de los ficheros CSV del proyecto de An√°lisis Acad√©mico con el fin de evaluar su calidad, estructura y posibles problemas antes de iniciar cualquier proceso de limpieza o transformaci√≥n. Esta fase es clave para desarrollar un criterio cr√≠tico sobre los datos.

---

## Ficheros Analizados

- Alumnos.csv
- Calificaciones.csv
- Cursos.csv
- Grupos.csv
- Horas.csv
- Modulos.csv
- Lineas.csv
- Procesos.csv
- Objetivos.csv
- Indicadores_Finales.csv

---

## An√°lisis General de los Ficheros

### Separador de columnas

En todos los ficheros analizados se observa el uso del separador punto y coma (`;`), lo cual es habitual en configuraciones regionales espa√±olas.

---

### Encabezados

Todos los ficheros contienen una primera fila con nombres de columnas. En general, los encabezados son descriptivos y permiten identificar correctamente el contenido de cada campo, aunque en algunos casos podr√≠an mejorarse para estandarizar nomenclaturas (por ejemplo, uso consistente de `id_`).

---

### Inspecci√≥n visual de los datos

Tras revisar las primeras filas de cada fichero se observan los siguientes patrones generales:

- Presencia de valores vac√≠os en algunos campos.
- Uso de valores como `N/A` o celdas en blanco.
- Campos num√©ricos almacenados como texto.
- Posibles inconsistencias en formatos (especialmente fechas o c√≥digos).

Estos problemas justifican la necesidad de una fase posterior de limpieza en la capa Plata.

---

## Identificaci√≥n de Claves e Identificadores

Durante la inspecci√≥n se han identificado campos que act√∫an como claves y permiten relacionar los distintos conjuntos de datos:

- **Alumnos.csv**
  - `id_alumno`

- **Calificaciones.csv**
  - `id_alumno`
  - `id_modulo`
  - `id_curso`

- **Modulos.csv**
  - `id_modulo`

- **Cursos.csv**
  - `id_curso`

- **Grupos.csv**
  - `id_grupo`

- **Indicadores_Finales.csv**
  - Identificadores temporales y de curso para comparativas anuales

Estas claves ser√°n fundamentales para el dise√±o del Data Warehouse en tareas posteriores.

---

## Problemas de Calidad Detectados

Los principales problemas detectados en esta primera inspecci√≥n son:

- Valores nulos o ausentes en campos relevantes.
- Falta de validaci√≥n en rangos num√©ricos (por ejemplo, notas).
- Inconsistencias en el tipo de dato esperado.
- Ausencia de restricciones que garanticen integridad referencial.

---

## Conclusi√≥n

Esta primera inspecci√≥n permite entender el estado real de los datos acad√©micos y justifica la necesidad de una arquitectura de procesamiento por capas. Los hallazgos de esta tarea servir√°n como base para definir las transformaciones de la capa Plata, el dise√±o del Data Warehouse y las pol√≠ticas de calidad y gobernanza del dato en el resto del proyecto.

----

# Tarea 2

### Estrutuca de data prevista

```
Carpetas/
|-- bronce/
|   |-- carga de datos [enesimo archivo]
|   |-- Filtro.py --> capa Plata[enesimo filtro]
|
|
|-- plata/
|   |-- A√±o/
|          |--Curso/
|                  |--notas
|
|
|-- Oro/
|   |-- PowerBI

```

Primero llegan los datos a la capa bronce, estos son procesados por el Filtro.py y luego enviado a carpeta Plata a sus respectivos lugares

# An√°lisis Acad√©mico ‚Äì Tarea 2: Arquitectura Data Lakehouse (Medall√≥n)

## Objetivo

Definir una arquitectura de datos basada en el patr√≥n **Medall√≥n (Bronce, Plata y Oro)** para el proyecto de An√°lisis Acad√©mico, teniendo en cuenta la frecuencia de actualizaci√≥n de los datos, la necesidad de conservar hist√≥ricos y su posterior explotaci√≥n anal√≠tica.

La arquitectura se implementa conceptualmente sobre **AWS S3**, utilizando distintos niveles de procesamiento para garantizar calidad, trazabilidad y eficiencia anal√≠tica.

---

## Contexto del Proyecto

- Los **datos acad√©micos** (calificaciones, alumnos, cursos, etc.) se actualizan **tras cada evaluaci√≥n** (tres veces al a√±o).
- Los **indicadores acad√©micos** se actualizan **una vez al a√±o**, al final del curso.
- Los informes utilizados por la direcci√≥n requieren **comparativas hist√≥ricas entre cursos acad√©micos**.

Este contexto justifica el uso de una arquitectura Lakehouse con separaci√≥n clara entre datos brutos, datos limpios y datos agregados.

---

## Arquitectura Medall√≥n

### üü§ Capa Bronce (Raw Data)

**Objetivo:**  
Almacenar los datos originales exactamente como se reciben, sin aplicar transformaciones, preservando su estado inicial para auditor√≠a y trazabilidad.

**Caracter√≠sticas:**

- Formato: CSV
- Datos sin limpiar ni validar
- Conservaci√≥n de hist√≥ricos
- Fuente directa de los sistemas acad√©micos

**Datasets almacenados:**

- Alumnos.csv
- Calificaciones.csv
- Cursos.csv
- Grupos.csv
- Horas.csv
- Modulos.csv
- Lineas.csv
- Procesos.csv
- Objetivos.csv
- Indicadores_Finales.csv

**Ejemplo de estructura en S3:**

- s3://academic-datalake/bronze/alumnos/year=2024/
- s3://academic-datalake/bronze/calificaciones/year=2024/
- s3://academic-datalake/bronze/indicadores/year=2024/

**Responsable:**  
Sistema de ingesta (por ejemplo, Apache NiFi o scripts automatizados).

---

### ü•à Capa Plata (Clean / Curated Data)

**Objetivo:**  
Aplicar procesos de limpieza, validaci√≥n y normalizaci√≥n sobre los datos procedentes de la capa Bronce para garantizar su calidad y consistencia.

**Transformaciones t√≠picas:**

- Eliminaci√≥n o tratamiento de valores nulos
- Validaci√≥n de rangos num√©ricos (por ejemplo, notas entre 0 y 10)
- Normalizaci√≥n de tipos de datos
- Estandarizaci√≥n de identificadores
- Correcci√≥n de inconsistencias detectadas en la Tarea 1

**Formato:**  

- Parquet (formato columnar y comprimido)

**Ejemplo de estructura en S3:**

- s3://academic-datalake/silver/alumnos/
- s3://academic-datalake/silver/calificaciones/
- s3://academic-datalake/silver/cursos/

**Responsable:**  
Ingeniero de Datos.

---

### ü•á Capa Oro (Business / Analytics)

**Objetivo:**  
Proporcionar datos agregados y optimizados para el an√°lisis acad√©mico, informes de direcci√≥n y cuadros de mando.

**Procesos aplicados:**

- Agregaciones por curso, m√≥dulo o evaluaci√≥n
- C√°lculo de medias, tasas de aprobados y comparativas interanuales
- Preparaci√≥n de datasets orientados a BI

**Ejemplos de datasets:**

- Rendimiento acad√©mico por curso
- Evoluci√≥n hist√≥rica de indicadores
- Comparativas entre evaluaciones

**Formato:**  

- Parquet

**Ejemplo de estructura en S3:**

- s3://academic-datalake/gold/rendimiento_academico/
- s3://academic-datalake/gold/indicadores_anuales/

**Responsable:**  
Analista BI / Cient√≠fico de Datos.

---

## Relaci√≥n con la Tarea 1

Los problemas de calidad detectados durante la inspecci√≥n inicial de los CSV (valores nulos, inconsistencias de formato, falta de validaciones) justifican la existencia de la capa Plata y definen las transformaciones necesarias antes de que los datos puedan ser explotados anal√≠ticamente.

---

## Conclusi√≥n

La arquitectura Medall√≥n permite estructurar el proyecto de An√°lisis Acad√©mico de forma escalable, trazable y alineada con las buenas pr√°cticas del ecosistema Big Data. La separaci√≥n por capas garantiza la preservaci√≥n de los datos originales, mejora la calidad del dato y facilita su explotaci√≥n para la toma de decisiones acad√©micas.

# An√°lisis Acad√©mico ‚Äì Tarea 3: Dise√±o del Data Warehouse (Kimball)

## Objetivo

Dise√±ar un Data Mart siguiendo la metodolog√≠a de Kimball mediante un **Esquema en Estrella** para el proyecto de An√°lisis Acad√©mico.

---

## Proceso de negocio

**Evaluaci√≥n acad√©mica / registro de calificaciones**.

---

## Grano (Grain)

**1 fila en la tabla de hechos = 1 calificaci√≥n de 1 alumno en 1 m√≥dulo para una evaluaci√≥n (trimestre) dentro de un curso acad√©mico (y opcionalmente un grupo).**

Este grano permite comparativas hist√≥ricas y an√°lisis por m√≥dulo, evaluaci√≥n y curso.

---

## Tabla de Hechos: `fact_calificaciones`

### Claves for√°neas (FK)

- `tiempo_key` ‚Üí `dim_tiempo`
- `alumno_key` ‚Üí `dim_alumno`
- `modulo_key` ‚Üí `dim_modulo`
- `curso_key` ‚Üí `dim_curso`
- `grupo_key` ‚Üí `dim_grupo` (opcional / recomendable)

### M√©tricas

- `nota` (decimal)
- `aprobado` (0/1, derivado de nota)
- `count_calificaciones` (1 por fila)

---

## Dimensiones

### `dim_tiempo`

- `tiempo_key` (PK, surrogate)
- `anio`
- `curso_academico`
- `evaluacion` / `trimestre`

### `dim_alumno`

- `alumno_key` (PK, surrogate)
- `id_alumno` (business key)
- atributos descriptivos disponibles (seg√∫n Alumnos.csv)

### `dim_modulo`

- `modulo_key` (PK, surrogate)
- `id_modulo` (business key)
- `nombre_modulo`
- atributos disponibles (seg√∫n Modulos.csv)

### `dim_curso`

- `curso_key` (PK, surrogate)
- `id_curso` (business key)
- `curso_academico`
- atributos disponibles (seg√∫n Cursos.csv)

### `dim_grupo` (si aplica)

- `grupo_key` (PK, surrogate)
- `id_grupo` (business key)
- nombre/c√≥digo de grupo

---

## Consideraci√≥n adicional: Indicadores anuales

Dado que los indicadores se actualizan una vez al a√±o, se recomienda un segundo Data Mart:

- `fact_indicadores` (hechos anuales)
- Dimensiones: `dim_tiempo`, `dim_linea`, `dim_proceso`, `dim_objetivo`

Esto separa el an√°lisis de calificaciones (trimestral) del an√°lisis de indicadores (anual) y facilita comparativas hist√≥ricas.

# An√°lisis Acad√©mico ‚Äì Tarea 4: De CSV a Parquet con Python y Pandas

## Objetivo

Convertir los ficheros CSV limpios del proyecto de An√°lisis Acad√©mico a formato Parquet utilizando Python y Pandas, aplicando transformaciones de limpieza, validaci√≥n de calidad y agregaci√≥n, con el fin de dejar los datos preparados para su uso en entornos Big Data.

---

## Dataset utilizado

- Calificaciones.csv

---

## Transformaciones aplicadas

### Transformaci√≥n 1 ‚Äì Limpieza

Se eliminan los registros con valores nulos en el campo de nota, detectados durante la inspecci√≥n inicial de los datos.

### Transformaci√≥n 2 ‚Äì Validaci√≥n de calidad

Se valida que las notas est√©n dentro del rango permitido (0 a 10) y se asegura su correcto tipo num√©rico.

### Agregaci√≥n final

Se calcula la nota media y el n√∫mero de alumnos por curso y m√≥dulo, generando un dataset orientado a an√°lisis acad√©mico.

---

## Conversi√≥n a Parquet

El resultado final se almacena en formato Parquet, un formato columnar y comprimido, adecuado para procesamiento anal√≠tico y herramientas Big Data.

---

## Resultado

- Fichero generado: `calificaciones_oro.parquet`
- Capa Medall√≥n: Oro
- Uso previsto: an√°lisis BI y comparativas acad√©micas

# An√°lisis Acad√©mico ‚Äì Tarea 5: Gobernanza y Calidad del Dato

## Objetivo

Definir los mecanismos de gobernanza del dato del proyecto de An√°lisis Acad√©mico mediante la creaci√≥n de un Cat√°logo de Datos y la documentaci√≥n del linaje del dato, garantizando trazabilidad, calidad y comprensi√≥n del ciclo de vida de la informaci√≥n.

---

## Data Catalog

El Data Catalog recoge todos los datasets del Data Lakehouse, indicando su capa Medall√≥n, formato, frecuencia de actualizaci√≥n y responsable. Este cat√°logo permite identificar r√°pidamente qu√© datos existen y cu√°l es su uso previsto.

El cat√°logo se mantiene en el fichero `DATA_CATALOG.xlsx`.

---

## Data Lineage

El Data Lineage documenta el flujo completo de los datos desde su origen en la capa Bronce hasta su consumo anal√≠tico en la capa Oro. Para cada transformaci√≥n se indican las reglas aplicadas y el responsable de la misma.

El linaje se mantiene en el fichero `DATA_LINEAGE.xlsx`.

---

## Calidad del Dato

Durante la capa Plata se aplican reglas de calidad orientadas a garantizar la fiabilidad de los datos acad√©micos, especialmente sobre la nota num√©rica:

- Eliminaci√≥n de valores nulos
- Validaci√≥n de tipo num√©rico
- Validaci√≥n de rango permitido (0‚Äì10)

Estas reglas aseguran que los datos consumidos en la capa Oro sean consistentes y aptos para an√°lisis e informes de direcci√≥n.

---

## Conclusi√≥n

La gobernanza del dato permite asegurar la trazabilidad, calidad y control del ciclo de vida de los datos acad√©micos. El uso de Data Catalog y Data Lineage facilita la auditor√≠a, el mantenimiento y la evoluci√≥n futura del proyecto.
